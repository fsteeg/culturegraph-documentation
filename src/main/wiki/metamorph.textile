h1. Metamorph

h2. Introduction

Metamorph is a Java library including an XML based data transformation language, designed to ease dealing with metadata. In this document the design rationale behind Metamorph is discussed, followed by a user guide including many hands-on code examples. As a conclusion several real-world application scenarios are presented.

Metadata is a central ingredient of any information storage and retrieval system. Being defined as ``data on data'', metadata provides descriptive information on the items stocked in the system; be it a library, an archive, a museum or a web search engine.

The variety of possibly stored items is reflected in the plethora of existing metadata formats. Obviously, a museum needs to describe its exposition items differently than a library its available books. And even the same book may be described differently depending on the institution holding it: A library has different description needs than a book seller. The first might use a standard such as Marc 21, the latter might use ONIX. Furthermore, standards also differ depending on the country or the language. Finally new technologies bring up new information needs not reflected in existing standards. New standards addressing the needs of the electronic age include for instance Dublin Core, METS and MODS.

In the face of a babylonic confusion of tongues, interoperability is an important issue, and metadata is transformed from one format to another on a regular basis. Transformations are not only performed to exchange data between institutions or to enable cross-collection searches. Metadata also needs to be transformed for indexing or for presentation in user-interfaces (on a webpage as HTML, for example). Despite being such an ubiquitous task, metadata transformation is still a tedious, mostly manual task, with scarce tool support. Software written to perform transformations is often coded from scratch for each and every individual case; despite great potential for component reuse.

The purpose of this document is to explain how the metadata challenge is addressed by Metamorph, a Java library including a domain specific metadata transformation language expressed in XML. In the next section the classical metadata transformation process will be sketched to elucidate the inherent challenges and to motivate the requirements and design goals of Metamorph. Next, the general architecture will be presented, followed by a description of the language features. Metamorph was applied in various projects at the German National Library. These application scenarios will be discussed below. A final section on the future prospects and limitations of Metamorph rounds up this document.

h2. Metadata Transformation in Practice

Metadata transformation is a complex and sometimes tedious process as its correctness depends on an overlap of domain knowledge and programming skills. First the typical procedure will be sketched followed by a discussion of the resulting challenges.

h3. Workflow

The first step is to create a Crosswalk or Conceptual Mapping between the two formats. Such a Conceptual Mapping normally consists of a table in human readable form and it is created and maintained by domain experts. The figure below shows two simple mapping rules from Pica to RDF, taken from the DNB Linked Data Service.

!figures/mapping_simple.PNG!
_Conceptual mapping for the DNB Linked Data Service_

On the left we see the respective fields in Pica, followed by an explanation of the content. Next, the target in RDF is defined, followed by remarks, indicating transformations applied to the data. The first line thus reads: Given a Pica+ recode, take the value of field @007P@ subfield @0@, prepend @DE-588b@ and write it to the RDF element @rdaGr2:identifierForTheCorporateBody@. The next figure shows a slightly more complex example. In this case values of different subfields need to be combined to fill the RDF element @gnd:preferredNameForTheCorporateBody@. The last column defines this combination by reference to the subfield names.

!figures/mapping_complex.PNG!
_A more complex mapping for the DNB Linked Data Service_

Based on the conceptual mapping, a piece of software is developed which implements the mapping. This is done by a programmer based the conceptual mapping document.

h3. Challenges

The just described workflow poses several challenges which shall now be briefly discussed. In the architecture section I will refer to them while introducing the architecture of Metamorph.

h4. From Concept to Code

The transition forms the conceptual mapping to the actual code implementing it is a critical one. A conceptual mapping leaves space for interpretation. The programmer is the one to fill this gap, although he or she lacks the knowledge of the domain specialist. Information flows one-way from domain specialist to programmer. What the programmer really implements cannot be double-checked by the domain specialist as he or she in turn lacks the fluency in the respective computer language the transformation is realized in.
		
h4. Format Independence

Conceptual mapping between metadata schemata bear a lot of resemblance. The table structure in which the mapping is described is almost always the same. The software side implementing the mappings differs significantly, though. This is due to encoding details of the metadata formats. For instance the code and data structures or classes used load and represent Marc 21 records and pica records in a Java program differ, even though conceptually they are very similar. Both are composed of fields containing subfields. Slight differences in the implementations renders reuse of the code infeasible.

h4. Performance

The input to a transformation from one format to another may well comprise millions of records. Performance is thus an issue. It is also important to note that transformations have to be performed repeatedly as the metadata keeps changing or errors in the mapping are discovered.

h2. Architecture

This section introduces the general architecture of Metamorph, pointing out how it addresses the requirements of reusability, transparency and performance.

h3. Generic Data Structure

At least in the library domain, the organization of the data within a record is fairly similar across formats (Marc, Pica and Mab2, for instance): A record consists of named fields, which in turn contain named subfields. The actual data is stored in these subfields. Many formats also store meta-information such as modification date in the ecord (which would actually be meta-meta-data, to be precise). Metadata formats in the archive domain in turn tend to exhibit more hierarchical structures. As pointed out above, a common denominator is needed to enable code reuse. Metamorph thus makes the assumption that the structure depicted in the next figure may serve as such a common denominator. The structure is fairly general and allows also for hierarchical structures. It turns out that most data structures found in common metadata formats can be mapped to it easily.

In general @Record@ forms a self contained and independent unit. It may contain Literals or Entities which themselves may contain further Entities or Literals. A Field in library metadata (e.g. Pica) would map to an Entity, Subfields to Literals. The recursive organization of Entities whould not be called on in this case.

!figures/record2_class.PNG!
_The abstract data model underlying Metamorph_

The universality of data structure described in the previous section comes at a cost. To generate it explicitly is costly as it comprises many Java object such as literals, lists or maps, depending on the specific implementation. Handling such generic data structures normally results in convoluted if-infested code. The solution to this dilemma is twofold: Firstly, as described in the next subsection we avoid ever explicitly instantiating the data structure in the figure above. Secondly, we use a domain specific language to handle transformation on the data stream, as sketched in below.

h3. Data as a Stream of Events

Do we really need to explicitly construct the data structure for each record? No, it turns out that it can be easily serialized to a stream of events. The listing below shows the interface, a receiver of such a stream needs to implement.

bc. 
public interface StreamReceiver {
    void startRecord(String identifier);
    void endRecord();
    void startEntity(String name);
    void endEntity();
    void literal(String name, String value);
}

_The interface used to serialize the data structure in the figure above_

Adding an interface such as the one in the next listing we can easily build processing chains using independent modules.

bc. 
public interface StreamSender {
	<R extends StreamReceiver> R setReceiver(R streamReceiver);
}

_The interface of an event stream sender. By virtue of the template R we can efficiently define processing chains via method chaining. See listing below for examples._

One module implementing @StreamSender@ for example might read a bibliographic record encoded in Pica and translating it to events. The events are received by another module which implements @StreamReceiver@ and @StreamSender@, thus forming a pipe or filter element in the chain. It may react on the events and transform the stream and its contents. Finally an arbitrary @StreamReceiver@ may form the endpoint of chain by reassembling the events to objects or persisting them to a database, logging them, indexing them. The interfaces shield the intricacies of one element in the chain from the others. This means that parts can be easily exchanged. The modularity gained by this schema enables reuse of software components and admits for a more flexible architecture.

Having modeled complex data as a stream of events, we can now build generic operation to be applied to this stream. Handling the stream and transforming it is the purpose of Metamorph which will be explained in the following section.

h2. Using Metamorph

The figure below shows the basic setup for data processing with Metamorph. The processing pipeline starts with the input data which is read by a reader specific to the input format. The reader emits messages according to the @StreamReceiver@ interface (see listing above). Due to this interface we are free to plug into the processing pipeline a variety of building blocks. In the majority of use cases the data needs to be transformed in one way or the other, a task that falls to the Metamorph object, depicted in the center of the figure below. The actual transformation performed by Metamorph is encoded in the Metamorph definition file. Finally, a writer condenses the event stream into the target data format.

!figures/readerwriter.PNG!
_A typical processing pipeline including a Metamorph object for data transformation_

This section explains the how such a setup is implemented in practice. Subsection _The Java Side_ is dedicated to the Java code needed to wire the pipeline parts together, subsection _Metamorph_ focuses on the Metamorph definition language.

h3. The Java Side

The follwing subsection explain how to create a Metamorph object, how to build a processing pipeline and how to handle exceptions.

h4. Creation

A new Metamorph is created by calling @build()@ on @MetamorphBuilder@. See listing below. Please note that the Metamorph object is not thread-safe.

bc. 
final Metamorph metamorph = MetamorphBuilder.build("definition.xml");

_Creating a Metamorph object based on a Metamorph description_

h4. Wiring

The Metamorph object acts as a pipe element in the data stream. See also the figure above. This means that we must wire it to a data source (or reader) and a data sink (or writer). The next listing shows how. First all elements of the processing chain are created. The wiring is done by calling @setReceiver()@.

The call returns its argument, preserving the respective type. Thus the calls can be chained to build up a pipeline as shown in the listing. Finally the processing is stared by calling the respective method on the data source/reader. The method name depends on the reader. In the Metamorph project @read()@ is used by convention.

bc. 
// create necessary objects
final PicaReader reader = new PicaReader();
final Metamorph metamorph = MetamorphBuilder.build("defnition.xml");
final ListMapWriter writer = new ListMapWriter();
//wire them
reader.setReceiver(metamorph).setReceiver(writer);
//start processing
reader.read(input);

_Putting together a processing pipeline according to the pattern in section 'Pipeline'_

The listing below shows a few more sophisticated wiring patterns, such as adding an additional element, junctions or splitters.

bc. 
//add logging
reader.setReceiver(new
LogPipe()).setReceiver(metamorph).setReceiver(writer);
//adding a tee junction
reader.setReceiver(new Tee()).setReceivers(writer1, writer2);
//splitting based on a metamorph description
final Splitter splitter = new Splitter("morph/typeSplitter.xml");
reader.setReceiver(splitter).setReceiver("Tn", writer1);
splitter.setReceiver("Tp", writer2);

_Advanced wiring_

h4. Error Handling

If an exception occurs during the processing of a stream of records, it is back propagated to the first element in the chain. This normally means that processing is terminated which may not be the preferred action. Imagine processing a million records. One normally prefers to log any error but continue the processing. For this reason an error handler may be registered with the Metamorph object. It catches all exceptions occurring in the Metamorph object and below. The next listing shows the respective code snippet.

bc. 
metamorph.setErrorHandler(new MetamorphErrorHandler() {
	@Override
	public void error(final Exception e) {
		// TODO fill in your error handling code
	}
});

_Registering an error handler_

h3. Metamorph Definition Language

The transformation a specific Metamoph instance performs are defined in a Metamorph definition in XML. See also figure above. The structure of the XML is constrained by a schema (@metamorph.xsd@). The listing below shows the high level organization of a Metamorph definition.

bc. 
<metamorph xmlns="http://www.culturegraph.org/metamorph"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://www.culturegraph.org/metamorph metamorph.xsd"
	entityMarker="." version="2">
	<meta><!-- Metadata --> </meta>
	<functions><!-- Function definitions --> </functions>
	<rules><!-- Transformation rules --> </rules>
	<maps><!-- Data maps --> </maps>
</metamorph>

_Structure of a Metamorph definition file_




